Voici le fichier `TASK.md`. Il est con√ßu comme un **Backlog Technique** pr√™t √† l'emploi.

J'ai d√©compos√© le plan en unit√©s de travail atomiques (ticketable items), en pr√©cisant pour chaque t√¢che la "Definition of Done" (DoD) technique. C'est le document de r√©f√©rence pour le d√©veloppeur (vous) au jour le jour.

---

# TASK.md - Backlog & Suivi d'Impl√©mentation

> **√âtat du Projet :** üèó Phase 1 (Infrastructure)
> **Sprint Actuel :** 01 - Genesis

Ce fichier liste les t√¢ches techniques n√©cessaires pour transformer `coleam00/habit-tracker` en un syst√®me **Agent Mesh**. Cochez les cases (`[x]`) au fur et √† mesure de votre progression.

---

## üõë Phase 0 : Pr√©requis & Environnement

*Avant de coder, l'√©tabli doit √™tre pr√™t.*

* [ ] **Setup Repository**
* [ ] Cloner `coleam00/habit-tracker`.
* [ ] Cr√©er la branche `feat/agent-mesh-init`.
* [ ] Restructurer les dossiers selon `README.md` (cr√©er `/infrastructure`, `/schemas`, `/agents`).


* [ ] **Acc√®s API**
* [ ] Obtenir cl√© API Anthropic (Claude) ou Google AI (Gemini).
* [ ] Cr√©er un fichier `.env` √† la racine (ne pas commiter !).



---

## üèó Phase 1 : Infrastructure (The Backbone)

*Priorit√© : Critique | Estimation : 1 jour*

### 1.1 Stack Docker Kafka

* [ ] **Cr√©er `infrastructure/docker-compose.yml**`
* [ ] Service: Zookeeper.
* [ ] Service: Kafka Broker (Port 9092).
* [ ] Service: Schema Registry (Port 8081).
* [ ] Service: Kafka UI (Port 8080) pour la visibilit√©.


* [ ] **Validation Infra**
* [ ] `docker-compose up -d` d√©marre sans erreur.
* [ ] Acc√®s √† Kafka UI sur `http://localhost:8080`.



### 1.2 D√©finition des Sch√©mas (Avro)

* [ ] **R√©diger `schemas/habit_log_recorded.avsc**`
* [ ] Champs requis : `user_id`, `habit_id`, `timestamp`.


* [ ] **R√©diger `schemas/pattern_detected.avsc**`
* [ ] Champs : `type`, `confidence`, `payload`.


* [ ] **R√©diger `schemas/agent_command.avsc**`
* [ ] Champs : `action`, `content`, `target`.



### 1.3 Automatisation du Registre

* [ ] **Script d'init**
* [ ] Cr√©er `infrastructure/register_schemas.py` (utilise `requests`).
* [ ] Le script doit poster les fichiers `.avsc` vers l'API du Schema Registry.
* [ ] **DoD :** Les "Subjects" apparaissent dans Kafka UI.



---

## üîå Phase 2 : Instrumentation Legacy (The Sensor)

*Priorit√© : Haute | Estimation : 1-2 jours*

### 2.1 Int√©gration Librairie

* [ ] Ajouter `confluent-kafka` et `fastavro` dans `requirements.txt` du backend existant.
* [ ] Installer les d√©pendances.

### 2.2 Module Producer

* [ ] **Cr√©er `backend/app/events/producer.py**`
* [ ] Classe singleton `EventProducer`.
* [ ] M√©thode `send_log(log_model)` qui s√©rialise en Avro.
* [ ] Gestion d'erreur (try/except) pour ne pas bloquer l'API si Kafka est down.



### 2.3 Hook API (FastAPI)

* [ ] **Modifier `backend/app/api/logs.py` (ou √©quivalent)**
* [ ] Dans le endpoint `POST /logs`, injecter l'appel `EventProducer.send_log()` apr√®s le `db.commit()`.


* [ ] **Test End-to-End manuel**
* [ ] Lancer l'app (`uvicorn`).
* [ ] Ajouter un log via le Frontend React.
* [ ] **DoD :** Voir le message appara√Ætre dans le topic `habit.telemetry.raw` via Kafka UI.



---

## üß† Phase 3 : Agent Observateur (Deterministic)

*Priorit√© : Moyenne | Estimation : 1 jour*

### 3.1 Skeleton Agent

* [ ] Cr√©er `agents/observer/main.py`.
* [ ] Impl√©menter une boucle `Consumer` basique (boucle while true).
* [ ] Configurer la d√©s√©rialisation Avro automatique.

### 3.2 Logique M√©tier (Streak)

* [ ] **Impl√©menter `StreakAnalyzer**`
* [ ] Garder en m√©moire (dict simple pour MVP) le dernier timestamp par `user_id`.
* [ ] Si `new_timestamp - last_timestamp > 48h`, lever une alerte.


* [ ] **Production d'Insight**
* [ ] Si alerte, publier un message Avro sur `habit.analysis.patterns`.
* [ ] **DoD :** Simuler 2 logs espac√©s de 3 jours et voir l'√©v√©nement `PatternDetected` sortir.



---

## ü§ñ Phase 4 : Agent Coach (Probabilistic / LLM)

*Priorit√© : Moyenne | Estimation : 2 jours*

### 4.1 Client LLM

* [ ] Cr√©er `agents/coach/llm_client.py`.
* [ ] Int√©grer LangChain ou client natif (Anthropic/Google).
* [ ] Tester un appel simple "Hello World".

### 4.2 System Prompting

* [ ] Cr√©er `agents/coach/prompts.py`.
* [ ] R√©diger le prompt syst√®me : *"You are a stoic habit coach. Receive analysis JSON, output succinct advice."*

### 4.3 Pipeline "Think-Act"

* [ ] **Consumer Loop**
* [ ] √âcouter `habit.analysis.patterns`.


* [ ] **D√©cision**
* [ ] Envoyer le pattern au LLM.
* [ ] Parser la r√©ponse du LLM.


* [ ] **Action**
* [ ] Publier le r√©sultat format√© (Avro) sur `agent.output.commands`.



---

## üì¢ Phase 5 : Actuators & Bouclage

*Priorit√© : Basse (MVP) | Estimation : 1 jour*

### 5.1 Service de Notification (Mock)

* [ ] Cr√©er `agents/notifier/main.py`.
* [ ] Consommer `agent.output.commands`.
* [ ] `print(f"SENDING PUSH TO {user}: {message}")`.

### 5.2 Documentation & Nettoyage

* [ ] Mettre √† jour le `README.md` principal avec les commandes pour lancer tous les agents (`docker-compose` ou scripts shell).
* [ ] Faire une d√©mo vid√©o (screen record) du flux complet.

---

## üêõ Backlog des Am√©liorations (Post-MVP)

* [ ] **Gestion de l'√©tat :** Remplacer le dictionnaire m√©moire de l'Observer par Redis ou Kafka Streams (KTable).
* [ ] **S√©curit√© :** Ajouter l'authentification SASL entre les agents et Kafka.
* [ ] **AgentOps :** Ajouter un `trace_id` qui traverse tout le cha√Ænage pour le debugging.